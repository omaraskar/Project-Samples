{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "Pclass Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "survival Survival (0 = No; 1 = Yes)\n",
    "name Name\n",
    "sex Sex\n",
    "age Age\n",
    "sibsp Number of Siblings/Spouses Aboard\n",
    "parch Number of Parents/Children Aboard\n",
    "ticket Ticket Number\n",
    "fare Passenger Fare (British pound)\n",
    "cabin Cabin\n",
    "embarked Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "boat Lifeboat\n",
    "body Body Identification Number\n",
    "home.dest Home/Destination\n",
    "'''\n",
    "\n",
    "df = pd.read_excel('titanic.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/askar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Some columns are irrelevant and df.drop(['body','name'], 1, inplace=True)\n",
    "df.convert_objects(convert_numeric=True)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace names to numeric values\n",
    "def handle_non_numerical_data(df):\n",
    "    columns = df.columns.values\n",
    "\n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            column_contents = df[column].values.tolist()\n",
    "            unique_elements = set(column_contents)\n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "\n",
    "            df[column] = list(map(convert_to_int, df[column]))\n",
    "\n",
    "    return df\n",
    "\n",
    "df = handle_non_numerical_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can start clustering using KMeans\n",
    "X = np.array(df.drop(['survived'], 1).astype(float))\n",
    "X = preprocessing.scale(X)\n",
    "y = np.array(df['survived'])\n",
    "\n",
    "clf = KMeans(n_clusters=2)\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7012987012987013\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = clf.predict(predict_me)\n",
    "    if prediction[0] == y[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try dropping some of the column to see if the accuracy is going to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6814362108479756\n"
     ]
    }
   ],
   "source": [
    "# Does whether of not the person got on a boat impact the survival chances?\n",
    "# Does the sex matter in the person being survived? It should..\n",
    "\n",
    "df.drop(['boat', 'sex'], axis = 1, inplace=True)\n",
    "# Now we can start clustering using KMeans\n",
    "X = np.array(df.drop(['survived'], 1).astype(float))\n",
    "X = preprocessing.scale(X)\n",
    "y = np.array(df['survived'])\n",
    "\n",
    "clf = KMeans(n_clusters=2)\n",
    "clf.fit(X)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = clf.predict(predict_me)\n",
    "    if prediction[0] == y[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hirarchial Clustering using MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanShift(bandwidth=None, bin_seeding=False, cluster_all=True, min_bin_freq=1,\n",
       "     n_jobs=1, seeds=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "df = pd.read_excel('titanic.xls')\n",
    "original_df = pd.DataFrame.copy(df)\n",
    "\n",
    "df.drop(['body','name'], 1, inplace=True)\n",
    "df.fillna(0,inplace=True)\n",
    "\n",
    "# Handle non-numeric data\n",
    "def handle_non_numerical_data(df):\n",
    "    columns = df.columns.values\n",
    "\n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:            \n",
    "            column_contents = df[column].values.tolist()\n",
    "            # Finding just the uniques\n",
    "            unique_elements = set(column_contents)\n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    # creating dict that contains new\n",
    "                    # id per unique string\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "            # now we map the new \"id\" vlaue\n",
    "            # to replace the string. \n",
    "            df[column] = list(map(convert_to_int,df[column]))\n",
    "\n",
    "    return df\n",
    "\n",
    "df = handle_non_numerical_data(df)\n",
    "df.drop(['ticket','home.dest'], 1, inplace=True)\n",
    "\n",
    "X = np.array(df.drop(['survived'], 1).astype(float))\n",
    "X = preprocessing.scale(X)\n",
    "y = np.array(df['survived'])\n",
    "\n",
    "# MeanShift model\n",
    "clf = MeanShift()\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store the clusters labels and centers\n",
    "labels = clf.labels_\n",
    "cluset_centers = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new column in the original dataset (before replacing \n",
    "# text with numbers so that we're able to comapare\n",
    "original_df['cluster_group']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/askar/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    original_df['cluster_group'].iloc[i] = labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.3719806763285024, 1: 0.6086956521739131, 2: 1.0, 3: 0.6, 4: 0.1}\n"
     ]
    }
   ],
   "source": [
    "n_clusters_ = len(np.unique(labels))\n",
    "survival_rates = {}\n",
    "for i in range(n_clusters_):\n",
    "    temp_df = original_df[ (original_df['cluster_group']==float(i)) ]\n",
    "    survival_cluster = temp_df[  (temp_df['survived'] == 1) ]\n",
    "    survival_rate = len(survival_cluster) / len(temp_df)\n",
    "    survival_rates[i] = survival_rate\n",
    "    \n",
    "print(survival_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on the dataset fed, the model thinks there's 4 clusters, first cluster 0 (corresponds to class 2 on the ship), has 37% survival rate, cluster 1 (first class passengers) has a 60% survival rate, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            pclass     survived         age        sibsp        parch  \\\n",
      "count  1242.000000  1242.000000  989.000000  1242.000000  1242.000000   \n",
      "mean      2.334138     0.371981   29.461240     0.429147     0.295491   \n",
      "std       0.816003     0.483528   14.297912     0.833555     0.647660   \n",
      "min       1.000000     0.000000    0.166700     0.000000     0.000000   \n",
      "25%       2.000000     0.000000   21.000000     0.000000     0.000000   \n",
      "50%       3.000000     0.000000   28.000000     0.000000     0.000000   \n",
      "75%       3.000000     1.000000   38.000000     1.000000     0.000000   \n",
      "max       3.000000     1.000000   80.000000     5.000000     4.000000   \n",
      "\n",
      "              fare        body  cluster_group  \n",
      "count  1241.000000  114.000000         1242.0  \n",
      "mean     25.605277  160.070175            0.0  \n",
      "std      30.267581   97.826351            0.0  \n",
      "min       0.000000    1.000000            0.0  \n",
      "25%       7.895800   70.500000            0.0  \n",
      "50%      13.000000  160.500000            0.0  \n",
      "75%      27.750000  255.750000            0.0  \n",
      "max     227.525000  328.000000            0.0  \n"
     ]
    }
   ],
   "source": [
    "print(original_df[(original_df['cluster_group'] == 0)].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
